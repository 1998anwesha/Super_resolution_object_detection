{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gdsr0uJ2paH"
      },
      "source": [
        "### SRGAN\n",
        "\n",
        "This notebook implements SRGAN model along with training and validation data creation."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/Super-resolution/SRGAN"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W63vYQgb2rdM",
        "outputId": "c46621be-b767-4ec4-f6c3-34f9df15f46f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Super-resolution/SRGAN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "jFun4__s2paK"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Import Library\n",
        "\"\"\"\n",
        "from torch import nn\n",
        "import h5py\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from collections import namedtuple\n",
        "import copy\n",
        "import math\n",
        "from torch.autograd import Variable\n",
        "import pandas as pd\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import random\n",
        "from torch import nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GkA-Uv8V2paL"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "SRGAN model\n",
        "\"\"\"\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, scale_factor):\n",
        "        upsample_block_num = int(math.log(scale_factor, 2))\n",
        "\n",
        "        super(Generator, self).__init__()\n",
        "        self.block1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=9, padding=4),\n",
        "            nn.PReLU()\n",
        "        )\n",
        "        self.block2 = ResidualBlock(32)\n",
        "        self.block3 = ResidualBlock(32)\n",
        "        self.block4 = ResidualBlock(32)\n",
        "        self.block5 = ResidualBlock(32)\n",
        "        self.block6 = ResidualBlock(32)\n",
        "        self.block7 = nn.Sequential(\n",
        "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32)\n",
        "        )\n",
        "        block8 = [UpsampleBLock(32, 2) for _ in range(upsample_block_num)]\n",
        "        block8.append(nn.Conv2d(32, 3, kernel_size=9, padding=4))\n",
        "        self.block8 = nn.Sequential(*block8)\n",
        "\n",
        "    def forward(self, x):\n",
        "        block1 = self.block1(x)\n",
        "        block2 = self.block2(block1)\n",
        "        block3 = self.block3(block2)\n",
        "        block4 = self.block4(block3)\n",
        "        block5 = self.block5(block4)\n",
        "        block6 = self.block6(block5)\n",
        "        block7 = self.block7(block6)\n",
        "        block8 = self.block8(block1 + block7)\n",
        "\n",
        "        return (torch.tanh(block8) + 1) / 2\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(512, 512, kernel_size=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(512, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        return torch.sigmoid(self.net(x).view(batch_size))\n",
        "\n",
        "\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, channels):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(channels)\n",
        "        self.prelu = nn.PReLU()\n",
        "        self.conv2 = nn.Conv2d(channels, channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = self.conv1(x)\n",
        "        residual = self.bn1(residual)\n",
        "        residual = self.prelu(residual)\n",
        "        residual = self.conv2(residual)\n",
        "        residual = self.bn2(residual)\n",
        "\n",
        "        return x + residual\n",
        "\n",
        "\n",
        "class UpsampleBLock(nn.Module):\n",
        "    def __init__(self, in_channels, up_scale):\n",
        "        super(UpsampleBLock, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, in_channels * up_scale ** 2, kernel_size=3, padding=1)\n",
        "        self.pixel_shuffle = nn.PixelShuffle(up_scale)\n",
        "        self.prelu = nn.PReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.pixel_shuffle(x)\n",
        "        x = self.prelu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N_BaMw8w2paM"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# Dataset feeding\n",
        "# \"\"\"\n",
        "# class CustomDataset(Dataset):\n",
        "#     def __init__(self, h5_file):\n",
        "#         super(CustomDataset, self).__init__()\n",
        "#         self.h5_file = h5_file\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         with h5py.File(self.h5_file, 'r') as f:\n",
        "#             return f['lr'][idx], f['hr'][idx]\n",
        "\n",
        "#     def __len__(self):\n",
        "#         with h5py.File(self.h5_file, 'r') as f:\n",
        "#             return len(f['lr'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "tsJlABxT2paN"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Loss Functions\n",
        "\"\"\"\n",
        "from torchvision.models.vgg import vgg16\n",
        "\n",
        "# TV loss is optional but implemented in paper\n",
        "class TVLoss(nn.Module):\n",
        "    def __init__(self, tv_loss_weight=1):\n",
        "        super(TVLoss, self).__init__()\n",
        "        self.tv_loss_weight = tv_loss_weight\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size()[0]\n",
        "        h_x = x.size()[2]\n",
        "        w_x = x.size()[3]\n",
        "        count_h = self.tensor_size(x[:, :, 1:, :])\n",
        "        count_w = self.tensor_size(x[:, :, :, 1:])\n",
        "        h_tv = torch.pow((x[:, :, 1:, :] - x[:, :, :h_x - 1, :]), 2).sum()\n",
        "        w_tv = torch.pow((x[:, :, :, 1:] - x[:, :, :, :w_x - 1]), 2).sum()\n",
        "        return self.tv_loss_weight * 2 * (h_tv / count_h + w_tv / count_w) / batch_size\n",
        "\n",
        "    @staticmethod\n",
        "    def tensor_size(t):\n",
        "        return t.size()[1] * t.size()[2] * t.size()[3]\n",
        "\n",
        "class GeneratorLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GeneratorLoss, self).__init__()\n",
        "        # use VGG16 for loss calculation\n",
        "        vgg = vgg16(pretrained=True, progress=False)\n",
        "        loss_network = nn.Sequential(*list(vgg.features)[:31]).eval()\n",
        "        for param in loss_network.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.loss_network = loss_network\n",
        "        self.mse_loss = nn.MSELoss()\n",
        "        self.tv_loss = TVLoss()\n",
        "\n",
        "    def forward(self, out_labels, out_images, target_images):\n",
        "        # Adversarial Loss\n",
        "        adversarial_loss = torch.mean(1 - out_labels)\n",
        "        # Perception Loss\n",
        "        perception_loss = self.mse_loss(self.loss_network(out_images), self.loss_network(target_images))\n",
        "        # Image Loss\n",
        "        image_loss = self.mse_loss(out_images, target_images)\n",
        "        # TV Loss\n",
        "        tv_loss = self.tv_loss(out_images)\n",
        "        return image_loss + 0.001 * adversarial_loss + 0.006 * perception_loss + 2e-8 * tv_loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtzH93D42paN"
      },
      "source": [
        "# Custom dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TC_vCjxM2paN"
      },
      "outputs": [],
      "source": [
        "# Custom dataset class to load images\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, lr_image_path, hr_image_path,num, transform=None):\n",
        "        \"\"\"\n",
        "        Custom dataset to load low-resolution (LR) and high-resolution (HR) images.\n",
        "\n",
        "        :param lr_image_path: Path to low-resolution images\n",
        "        :param hr_image_path: Path to high-resolution images\n",
        "        :param transform: Optional transformation to apply to images\n",
        "        \"\"\"\n",
        "        self.lr_image_path = lr_image_path\n",
        "        self.hr_image_path = hr_image_path\n",
        "        self.transform = transform\n",
        "\n",
        "        # Get list of image file paths\n",
        "        self.lr_image_list = glob.glob(lr_image_path)[:num]\n",
        "        self.hr_image_list = glob.glob(hr_image_path)[:num]\n",
        "\n",
        "        # Shuffle the lists (optional)\n",
        "        random.shuffle(self.lr_image_list)\n",
        "        random.shuffle(self.hr_image_list)\n",
        "\n",
        "        # Ensure both lists have the same length (minimum of the two lengths)\n",
        "        self.num_images = min(len(self.lr_image_list), len(self.hr_image_list))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Open the images (convert them to RGB)\n",
        "        lr_image = Image.open(self.lr_image_list[idx]).convert('RGB')\n",
        "        hr_image = Image.open(self.hr_image_list[idx]).convert('RGB')\n",
        "\n",
        "        # Convert images to numpy arrays\n",
        "        lr_image = np.array(lr_image).astype(np.float32)\n",
        "        hr_image = np.array(hr_image).astype(np.float32)\n",
        "\n",
        "        # Transpose to match PyTorch image format (C, H, W)\n",
        "        lr_image = np.transpose(lr_image, axes=[2, 0, 1])  # Convert to C, H, W\n",
        "        hr_image = np.transpose(hr_image, axes=[2, 0, 1])  # Convert to C, H, W\n",
        "\n",
        "        # Normalize the image to [0, 1] range\n",
        "        lr_image /= 255.0\n",
        "        hr_image /= 255.0\n",
        "\n",
        "        # Apply any transformations if provided\n",
        "        if self.transform:\n",
        "            lr_image = self.transform(lr_image)\n",
        "            hr_image = self.transform(hr_image)\n",
        "\n",
        "        return lr_image, hr_image\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "duHxtnFZ2paO"
      },
      "outputs": [],
      "source": [
        "# Create DataLoader for training and evaluation datasets\n",
        "def create_dataloader(lr_image_path, hr_image_path,num, batch_size=1):\n",
        "    dataset = CustomDataset(lr_image_path, hr_image_path,num)\n",
        "    dataloader = DataLoader(dataset=dataset,\n",
        "                            batch_size=batch_size,\n",
        "                            shuffle=True,\n",
        "                            num_workers=0,\n",
        "                            pin_memory=True,\n",
        "                            drop_last=True)\n",
        "    return dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Pi4jC51n2paP"
      },
      "outputs": [],
      "source": [
        "# Set paths to the directories containing LR and HR images\n",
        "lr_train_dir = 'train/images_stage5/*.png'  # Path for low-resolution training images\n",
        "hr_train_dir = 'train/images_stage3/*.png'  # Path for high-resolution training images\n",
        "\n",
        "# Set paths to the directories containing LR and HR images for validation set\n",
        "lr_valid_dir = 'valid/images_stage5/*.png'  # Path for low-resolution validation images\n",
        "hr_valid_dir = 'valid/images_stage3/*.png'  # Path for high-resolution validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "fschrvAm2paQ"
      },
      "outputs": [],
      "source": [
        "train_dataset = CustomDataset(lr_train_dir, hr_train_dir, num=1000)\n",
        "\n",
        "# Create DataLoader for training\n",
        "train_dataloader = create_dataloader(lr_train_dir, hr_train_dir,1000, batch_size=4)\n",
        "\n",
        "eval_dataset = CustomDataset(lr_valid_dir, hr_valid_dir, num=100)\n",
        "\n",
        "# Create DataLoader for evaluation\n",
        "eval_dataloader = create_dataloader(lr_valid_dir, hr_valid_dir, 100,batch_size=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSn-6sfI2paQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8fmf5raG2paQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Setup network parameter\n",
        "\"\"\"\n",
        "upscale_factor = 4\n",
        "num_epoch = 1  #20\n",
        "\n",
        "torch.manual_seed(123)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oflHiVL72paQ",
        "outputId": "a4f9d73a-44a5-41f5-fec4-2b3b422234a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "Setup network\n",
        "\"\"\"\n",
        "netG = Generator(upscale_factor)\n",
        "netD = Discriminator()\n",
        "generator_criterion = GeneratorLoss()\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    netG.to(device)\n",
        "    netD.to(device)\n",
        "    generator_criterion.to(device)\n",
        "\n",
        "optimizerG = optim.Adam(netG.parameters())\n",
        "optimizerD = optim.Adam(netD.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3UCtB5VX2paQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Util function to measure error\n",
        "\"\"\"\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "\"\"\"\n",
        "Calculate PSNR\n",
        "\"\"\"\n",
        "def calc_psnr(img1, img2):\n",
        "    return 10. * torch.log10(1. / torch.mean((img1 - img2) ** 2))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwkU29wR2paQ",
        "outputId": "741a31da-a74d-4dbe-a16b-3c6ab623ef7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[1/1] Loss_D: 0.2191 Loss_G: 0.0353 D(x): 0.9082 D(G(z)): 0.1273: 100%|██████████| 1000/1000 [12:51<00:00,  1.30it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval psnr: 15.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': []}\n",
        "best_weights = copy.deepcopy(netG.state_dict())\n",
        "best_epoch = 0\n",
        "best_psnr = 0.0\n",
        "\n",
        "for epoch in range(1, num_epoch + 1):\n",
        "\n",
        "    epoch_losses = AverageMeter()\n",
        "    netG.train()\n",
        "    netD.train()\n",
        "\n",
        "    with tqdm(total=(len(train_dataset) - len(train_dataset) % 1)) as t:\n",
        "        t.set_description('epoch: {}/{}'.format(epoch, num_epoch))\n",
        "\n",
        "        running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "        # training\n",
        "        netG.train()\n",
        "        netD.train()\n",
        "\n",
        "        for data in train_dataloader:\n",
        "            inputs, labels = data\n",
        "\n",
        "            g_update_first = True\n",
        "            batch_size = inputs.size(0)\n",
        "            running_results['batch_sizes'] += batch_size\n",
        "\n",
        "            # Update D network\n",
        "            real_img = Variable(labels).to(device, dtype=torch.float)\n",
        "            z = Variable(inputs).to(device, dtype=torch.float)\n",
        "\n",
        "            fake_img = netG(z)\n",
        "\n",
        "            netD.zero_grad()\n",
        "            real_out = netD(real_img).mean()\n",
        "            fake_out = netD(fake_img).mean()\n",
        "            d_loss = 1 - real_out + fake_out\n",
        "            d_loss.backward(retain_graph=True)\n",
        "\n",
        "            # Update G network\n",
        "            netG.zero_grad()\n",
        "            g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "            g_loss.backward()\n",
        "\n",
        "            epoch_losses.update(g_loss.item(), len(inputs))\n",
        "\n",
        "            optimizerD.step()\n",
        "            optimizerG.step()\n",
        "\n",
        "            # Loss for current batch\n",
        "            running_results['g_loss'] += g_loss.item() * batch_size\n",
        "            running_results['d_loss'] += d_loss.item() * batch_size\n",
        "            running_results['d_score'] += real_out.item() * batch_size\n",
        "            running_results['g_score'] += fake_out.item() * batch_size\n",
        "\n",
        "            t.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "                epoch, num_epoch, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "                running_results['g_loss'] / running_results['batch_sizes'],\n",
        "                running_results['d_score'] / running_results['batch_sizes'],\n",
        "                running_results['g_score'] / running_results['batch_sizes']))\n",
        "            t.update(len(inputs))\n",
        "\n",
        "        torch.save(netG.state_dict(), 'weight_srgan/netG_epoch_%d.pth' % epoch)\n",
        "        torch.save(netD.state_dict(), 'weight_srgan/netD_epoch_%d.pth' % epoch)\n",
        "\n",
        "        # validation\n",
        "        netG.eval()\n",
        "        epoch_psnr = AverageMeter()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_images = []\n",
        "            for data in eval_dataloader:\n",
        "                inputs, labels = data\n",
        "                inputs = inputs.to(device, dtype=torch.float)\n",
        "                labels = labels.to(device, dtype=torch.float)\n",
        "\n",
        "                preds = netG(inputs)\n",
        "\n",
        "                epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
        "\n",
        "            print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
        "\n",
        "            if epoch_psnr.avg > best_psnr:\n",
        "                best_epoch = epoch\n",
        "                best_psnr = epoch_psnr.avg\n",
        "                best_weights = copy.deepcopy(netG.state_dict())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SWeWtPua2paR"
      },
      "outputs": [],
      "source": [
        "# \"\"\"\n",
        "# Evaluate the model with test set\n",
        "# \"\"\"\n",
        "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# model = Generator(upscale_factor).to(device)\n",
        "# state_dict = model.state_dict()\n",
        "# for n, p in torch.load('weight_srgan/netG_epoch_1.pth', map_location=lambda storage, loc: storage).items():\n",
        "#     if n in state_dict.keys():\n",
        "#         state_dict[n].copy_(p)\n",
        "#     else:\n",
        "#         raise KeyError(n)\n",
        "\n",
        "# model.eval()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GWLK2NDj2paR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading pretrained weights"
      ],
      "metadata": {
        "id": "uQShEcmHp6rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths to the saved weights\n",
        "generator_path = 'weight_srgan/netG_epoch_1.pth'  # Replace with the desired epoch\n",
        "discriminator_path = 'weight_srgan/netD_epoch_1.pth'\n",
        "\n",
        "# Load model weights\n",
        "netG.load_state_dict(torch.load(generator_path,map_location=torch.device('cpu') ))\n",
        "netD.load_state_dict(torch.load(discriminator_path,map_location=torch.device('cpu') ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EnJNP1CzmZyz",
        "outputId": "16d99843-8b8d-40a5-9600-404cd1a0ac33"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-f8b7dd2f9de8>:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  netG.load_state_dict(torch.load(generator_path,map_location=torch.device('cpu') ))\n",
            "<ipython-input-16-f8b7dd2f9de8>:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  netD.load_state_dict(torch.load(discriminator_path,map_location=torch.device('cpu') ))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# results = {'d_loss': [], 'g_loss': [], 'd_score': [], 'g_score': [], 'psnr': []}\n",
        "# best_weights = copy.deepcopy(netG.state_dict())\n",
        "# best_epoch = 0\n",
        "# best_psnr = 0.0\n",
        "\n",
        "# for epoch in range(2, num_epoch + 2):\n",
        "\n",
        "#     epoch_losses = AverageMeter()\n",
        "#     netG.train()\n",
        "#     netD.train()\n",
        "\n",
        "#     with tqdm(total=(len(train_dataset) - len(train_dataset) % 1)) as t:\n",
        "#         t.set_description('epoch: {}/{}'.format(epoch, num_epoch))\n",
        "\n",
        "#         running_results = {'batch_sizes': 0, 'd_loss': 0, 'g_loss': 0, 'd_score': 0, 'g_score': 0}\n",
        "\n",
        "#         # training\n",
        "#         netG.train()\n",
        "#         netD.train()\n",
        "\n",
        "#         for data in train_dataloader:\n",
        "#             inputs, labels = data\n",
        "\n",
        "#             g_update_first = True\n",
        "#             batch_size = inputs.size(0)\n",
        "#             running_results['batch_sizes'] += batch_size\n",
        "\n",
        "#             # Update D network\n",
        "#             real_img = Variable(labels).to(device, dtype=torch.float)\n",
        "#             z = Variable(inputs).to(device, dtype=torch.float)\n",
        "\n",
        "#             fake_img = netG(z)\n",
        "\n",
        "#             netD.zero_grad()\n",
        "#             real_out = netD(real_img).mean()\n",
        "#             fake_out = netD(fake_img).mean()\n",
        "#             d_loss = 1 - real_out + fake_out\n",
        "#             d_loss.backward(retain_graph=True)\n",
        "\n",
        "#             # Update G network\n",
        "#             netG.zero_grad()\n",
        "#             g_loss = generator_criterion(fake_out, fake_img, real_img)\n",
        "#             g_loss.backward()\n",
        "\n",
        "#             epoch_losses.update(g_loss.item(), len(inputs))\n",
        "\n",
        "#             optimizerD.step()\n",
        "#             optimizerG.step()\n",
        "\n",
        "#             # Loss for current batch\n",
        "#             running_results['g_loss'] += g_loss.item() * batch_size\n",
        "#             running_results['d_loss'] += d_loss.item() * batch_size\n",
        "#             running_results['d_score'] += real_out.item() * batch_size\n",
        "#             running_results['g_score'] += fake_out.item() * batch_size\n",
        "\n",
        "#             t.set_description(desc='[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f' % (\n",
        "#                 epoch, num_epoch, running_results['d_loss'] / running_results['batch_sizes'],\n",
        "#                 running_results['g_loss'] / running_results['batch_sizes'],\n",
        "#                 running_results['d_score'] / running_results['batch_sizes'],\n",
        "#                 running_results['g_score'] / running_results['batch_sizes']))\n",
        "#             t.update(len(inputs))\n",
        "\n",
        "#         torch.save(netG.state_dict(), 'weight_srgan/netG_epoch_%d.pth' % epoch)\n",
        "#         torch.save(netD.state_dict(), 'weight_srgan/netD_epoch_%d.pth' % epoch)\n",
        "\n",
        "#         # validation\n",
        "#         netG.eval()\n",
        "#         epoch_psnr = AverageMeter()\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             val_images = []\n",
        "#             for data in eval_dataloader:\n",
        "#                 inputs, labels = data\n",
        "#                 inputs = inputs.to(device, dtype=torch.float)\n",
        "#                 labels = labels.to(device, dtype=torch.float)\n",
        "\n",
        "#                 preds = netG(inputs)\n",
        "\n",
        "#                 epoch_psnr.update(calc_psnr(preds, labels), len(inputs))\n",
        "\n",
        "#             print('eval psnr: {:.2f}'.format(epoch_psnr.avg))\n",
        "\n",
        "#             if epoch_psnr.avg > best_psnr:\n",
        "#                 best_epoch = epoch\n",
        "#                 best_psnr = epoch_psnr.avg\n",
        "#                 best_weights = copy.deepcopy(netG.state_dict())"
      ],
      "metadata": {
        "id": "dBGCvXb4pb1Q"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmqcSGZSptRm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
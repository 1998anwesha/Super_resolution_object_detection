{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c27167-032c-4e9d-9ba6-0b3a6cbd8468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
    "from datasets import SRDataset\n",
    "import random\n",
    "from torch.utils.data import Subset\n",
    "import os\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97702992-93f0-40ef-8cd0-4a81d10d6451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the test set folder and output folder\n",
    "original_test_folder = \"dota/test/images_large\"\n",
    "resized_test_folder = \"dota/test/images\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(resized_test_folder, exist_ok=True)\n",
    "\n",
    "# Define the transformation for resizing\n",
    "resize_transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 1024))  # Resize to 1024x1024\n",
    "])\n",
    "\n",
    "# Loop through all images in the test set folder\n",
    "print(\"Resizing test set images...\")\n",
    "for image_name in tqdm(os.listdir(original_test_folder)):\n",
    "    # Full path to the original image\n",
    "    original_image_path = os.path.join(original_test_folder, image_name)\n",
    "    \n",
    "    # Open the image using PIL\n",
    "    with Image.open(original_image_path) as img:\n",
    "        # Apply the resizing transformation\n",
    "        resized_img = resize_transform(img)\n",
    "        \n",
    "        # Save the resized image to the new folder\n",
    "        resized_image_path = os.path.join(resized_test_folder, image_name)\n",
    "        resized_img.save(resized_image_path)\n",
    "\n",
    "print(f\"Resized images are saved to {resized_test_folder}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "526cb1d8-1e58-47db-aa3f-aa9b092e1ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data\n",
    "data_folder = \"./\"\n",
    "test_data_names = [\"dota/test/images\"] #[\"Set5\", \"Set14\", \"BSDS100\"]\n",
    "\n",
    "# Model checkpoints\n",
    "srgan_checkpoint = \"./checkpoint_srgan.pth.tar\"\n",
    "srresnet_checkpoint = \"./checkpoint_srresnet.pth.tar\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f240995-40e9-4078-9a2d-67c155fe1801",
   "metadata": {},
   "source": [
    "# Evaluate SRGAN on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b46ae03-2eb5-44a5-9102-2f47b087e250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model, either the SRResNet or the SRGAN\n",
    "srgan_generator = torch.load(srgan_checkpoint,weights_only=False)['generator'].to(device)\n",
    "srgan_generator.eval()\n",
    "model = srgan_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d7bc25d-e5b5-4aae-9ff4-871427a11d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "def test_eval(model):\n",
    "    for test_data_name in test_data_names:\n",
    "        print(\"\\nFor %s:\\n\" % test_data_name)\n",
    "    \n",
    "        # Custom dataloader\n",
    "        test_dataset = SRDataset(data_folder,\n",
    "                                 split='test',\n",
    "                                 crop_size=0,\n",
    "                                 scaling_factor=4,\n",
    "                                 lr_img_type='imagenet-norm',\n",
    "                                 hr_img_type='[-1, 1]',\n",
    "                                 test_data_name=test_data_name)\n",
    "    \n",
    "        # Randomly sample a subset if needed\n",
    "        num_samples = 469  # Or the size of the full test set if no limit is needed\n",
    "        total_samples = len(test_dataset)\n",
    "        selected_indices = random.sample(range(total_samples), num_samples)  # Use `range(total_samples)` for full dataset\n",
    "        test_dataset_subset = Subset(test_dataset, selected_indices)\n",
    "    \n",
    "        # Create a DataLoader for the smaller dataset\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset_subset, batch_size=1, shuffle=False, num_workers=1, pin_memory=True)\n",
    "        print(f\"Test set size: {len(test_dataset_subset)}\")\n",
    "    \n",
    "        # Lists to store PSNRs and SSIMs for individual images\n",
    "        psnr_list = []\n",
    "        ssim_list = []\n",
    "    \n",
    "        # Prohibit gradient computation explicitly\n",
    "        with torch.no_grad():\n",
    "            for i, (lr_imgs, hr_imgs) in enumerate(test_loader):\n",
    "                # Move to default device\n",
    "                lr_imgs = lr_imgs.to(device)  # (batch_size (1), 3, w / 4, h / 4), imagenet-normed\n",
    "                hr_imgs = hr_imgs.to(device)  # (batch_size (1), 3, w, h), in [-1, 1]\n",
    "    \n",
    "                # Forward prop.\n",
    "                sr_imgs = model(lr_imgs)  # (1, 3, w, h), in [-1, 1]\n",
    "    \n",
    "                # Calculate PSNR and SSIM\n",
    "                sr_imgs_y = convert_image(sr_imgs, source='[-1, 1]', target='y-channel').squeeze(\n",
    "                    0)  # (w, h), in y-channel\n",
    "                hr_imgs_y = convert_image(hr_imgs, source='[-1, 1]', target='y-channel').squeeze(0)  # (w, h), in y-channel\n",
    "    \n",
    "                psnr = peak_signal_noise_ratio(hr_imgs_y.cpu().numpy(), sr_imgs_y.cpu().numpy(), data_range=255.)\n",
    "                ssim = structural_similarity(hr_imgs_y.cpu().numpy(), sr_imgs_y.cpu().numpy(), data_range=255.)\n",
    "    \n",
    "                # Append PSNR and SSIM to the lists\n",
    "                psnr_list.append(psnr)\n",
    "                ssim_list.append(ssim)\n",
    "    \n",
    "                #print(f\"Image {i + 1}: PSNR = {psnr:.3f}, SSIM = {ssim:.3f}\")\n",
    "    \n",
    "        # Print average PSNR and SSIM\n",
    "        avg_psnr = sum(psnr_list) / len(psnr_list)\n",
    "        avg_ssim = sum(ssim_list) / len(ssim_list)\n",
    "        print(f\"\\nAverage PSNR: {avg_psnr:.3f}\")\n",
    "        print(f\"Average SSIM: {avg_ssim:.3f}\")\n",
    "        return avg_psnr, avg_ssim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "589e16e3-647e-41a7-be42-153bb3b12e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dota/test/images:\n",
      "\n",
      "Test set size: 469\n",
      "\n",
      "Average PSNR: 28.840\n",
      "Average SSIM: 0.786\n"
     ]
    }
   ],
   "source": [
    "avg_psnr_srgan, avg_ssim_srgan = test_eval(model) #SRGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f29cbb-0257-4212-89f6-ca887dd88f10",
   "metadata": {},
   "source": [
    "# Evaluate SRResNet on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5c4b4922-ffa6-4b89-8336-ab777ea700c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SRResNet\n"
     ]
    }
   ],
   "source": [
    "srresnet = torch.load(srresnet_checkpoint, weights_only=False)['model'].to(device)\n",
    "srresnet.eval()\n",
    "print(\"Evaluating SRResNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b37b390e-a57c-421b-8e62-e4bc1a8507d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For dota/test/images:\n",
      "\n",
      "Test set size: 469\n",
      "\n",
      "Average PSNR: 31.880\n",
      "Average SSIM: 0.865\n"
     ]
    }
   ],
   "source": [
    "avg_psnr_srresnet, avg_ssim_srresnet = test_eval(srresnet) #SRResnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907d49cc-1e4d-443a-b4eb-d209da526ee2",
   "metadata": {},
   "source": [
    "# Create results table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "245d1c23-9d4a-4be6-a61c-81ce3036f7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results from the evaluations\n",
    "results = {\n",
    "    \"Model\": [\"SRGAN\", \"SRResNet\"],\n",
    "    \"Average PSNR\": [avg_psnr_srgan, avg_psnr_srresnet],\n",
    "    \"Average SSIM\": [avg_ssim_srgan, avg_ssim_srresnet]\n",
    "}\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e591fc9-af19-423d-bc6a-1e1ead453717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_e04cf th {\n",
       "  font-size: 20px;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "  border: 2px solid black;\n",
       "}\n",
       "#T_e04cf td {\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "  text-align: center;\n",
       "  border: 2px solid black;\n",
       "}\n",
       "#T_e04cf table {\n",
       "  border: 2px solid black;\n",
       "  border-collapse: collapse;\n",
       "}\n",
       "#T_e04cf_row0_col0, #T_e04cf_row0_col1, #T_e04cf_row0_col2 {\n",
       "  background-color: lightblue;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "}\n",
       "#T_e04cf_row1_col0, #T_e04cf_row1_col1, #T_e04cf_row1_col2 {\n",
       "  background-color: lightgreen;\n",
       "  font-size: 18px;\n",
       "  font-weight: bold;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_e04cf\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_e04cf_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_e04cf_level0_col1\" class=\"col_heading level0 col1\" >Average PSNR</th>\n",
       "      <th id=\"T_e04cf_level0_col2\" class=\"col_heading level0 col2\" >Average SSIM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_e04cf_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_e04cf_row0_col0\" class=\"data row0 col0\" >SRGAN</td>\n",
       "      <td id=\"T_e04cf_row0_col1\" class=\"data row0 col1\" >28.840011</td>\n",
       "      <td id=\"T_e04cf_row0_col2\" class=\"data row0 col2\" >0.785837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_e04cf_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_e04cf_row1_col0\" class=\"data row1 col0\" >SRResNet</td>\n",
       "      <td id=\"T_e04cf_row1_col1\" class=\"data row1 col1\" >31.879947</td>\n",
       "      <td id=\"T_e04cf_row1_col2\" class=\"data row1 col2\" >0.865299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28fa0ea1890>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to style rows with colored backgrounds\n",
    "def highlight_rows(row):\n",
    "    color = \"lightblue\" if row[\"Model\"] == \"SRGAN\" else \"lightgreen\"\n",
    "    return [f\"background-color: {color}; font-size: 18px; font-weight: bold;\"] * len(row)\n",
    "\n",
    "# Apply the styling function\n",
    "styled_df = df.style.apply(highlight_rows, axis=1)\n",
    "\n",
    "# Apply global styles for all text and borders around cells\n",
    "styled_df = styled_df.set_table_styles([\n",
    "    {\"selector\": \"th\", \"props\": [(\"font-size\", \"20px\"), (\"font-weight\", \"bold\"), (\"text-align\", \"center\"), (\"border\", \"2px solid black\")]},\n",
    "    {\"selector\": \"td\", \"props\": [(\"font-size\", \"18px\"), (\"font-weight\", \"bold\"), (\"text-align\", \"center\"), (\"border\", \"2px solid black\")]},\n",
    "    {\"selector\": \"table\", \"props\": [(\"border\", \"2px solid black\"), (\"border-collapse\", \"collapse\")]}\n",
    "])\n",
    "\n",
    "# Display the styled dataframe (works in Jupyter Notebook or HTML-supported environments)\n",
    "styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590f1895-0bfa-434c-8b7a-acde553ed296",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7eda9c-1925-4826-8c1f-e8c8e0831474",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7217329d-2755-4301-9053-1dc29ea683e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
